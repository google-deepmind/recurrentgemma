{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J72yaKjJEXip"
      },
      "source": [
        "Copyright 2024 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRShUtLfEXiq"
      },
      "source": [
        "# GSM8K evaluation using RecurrentGemma\n",
        "\n",
        "The [GSM8K dataset](https://arxiv.org/pdf/2110.14168.pdf) presents a good evaluation challenge for small models for several reasons:\n",
        "\n",
        "1. **Conceptual Simplicity:** While the problems in GSM8K require multi-step reasoning, they primarily involve elementary mathematical concepts and basic arithmetic operations. This makes the dataset accessible to smaller models that may not have the capacity to handle complex mathematical reasoning.\n",
        "\n",
        "2. **Linguistic Diversity:** GSM8K emphasizes linguistic diversity, ensuring that problems are not simply variations of the same template. This forces models to generalize their understanding of language and mathematical concepts, rather than relying on superficial pattern matching.\n",
        "\n",
        "3. **Moderate Difficulty:** The problems in GSM8K are challenging enough to test the limits of small models without being completely intractable. This allows for meaningful evaluation and comparison of different models and methods within a reasonable difficulty range.\n",
        "\n",
        "4. **Natural Language Solutions:** GSM8K provides solutions in natural language, encouraging models to develop verbal analytical skills and produce human-interpretable reasoning steps. This is particularly relevant for smaller models that may struggle with purely symbolic or equation-based solutions.\n",
        "\n",
        "By focusing on grade-school math concepts and emphasizing linguistic diversity, GSM8K provides a valuable benchmark for evaluating the informal reasoning abilities of smaller language models and identifying areas for improvement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMv_56WyEXiq"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIF7Tr8yEXiq"
      },
      "outputs": [],
      "source": [
        "! pip install git+https://github.com/google-deepmind/recurrentgemma.git#egg=recurrentgemma[jax]\n",
        "! pip install --user kaggle\n",
        "! pip install datasets  # Required for the task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucx1AgltaZRF"
      },
      "source": [
        "## Downloading the checkpoint\n",
        "\n",
        "\"To use RecurrentGemma's checkpoints, you'll need a Kaggle account and API key. Here's how to get them:\n",
        "\n",
        "1. Visit https://www.kaggle.com/ and create an account.\n",
        "2. Go to your account settings, then the 'API' section.\n",
        "3. Click 'Create new token' to download your key.\n",
        "4. You can either login using the UI interface or by setting your Kaggle username and key via the Colab secrets.\n",
        "\n",
        "Then run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qai-J2Dgaac0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import kagglehub\n",
        "\n",
        "try:\n",
        "  os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "  os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "except userdata.SecretNotFoundError:\n",
        "  kagglehub.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSv5uG5_acQk"
      },
      "source": [
        "If everything went well, you should see:\n",
        "```\n",
        "Kaggle credentials set.\n",
        "Kaggle credentials successfully validated.\n",
        "```\n",
        "\n",
        "Now select and download the checkpoint you want to try."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46zzoC9Adqsr"
      },
      "outputs": [],
      "source": [
        "# @title Python imports\n",
        "\n",
        "import pathlib\n",
        "import re\n",
        "import datasets\n",
        "\n",
        "import sentencepiece as spm\n",
        "from recurrentgemma import jax as recurrentgemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uHzK733EXiq"
      },
      "outputs": [],
      "source": [
        "VARIANT = '2b' # @param ['2b', '2b-it'] {type:\"string\"}\n",
        "weights_dir = kagglehub.model_download(f'google/recurrentgemma/flax/{VARIANT}')\n",
        "weights_dir = pathlib.Path(weights_dir)\n",
        "ckpt_path = weights_dir / VARIANT\n",
        "vocab_path = weights_dir / 'tokenizer.model'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNEpwGyREXiq"
      },
      "source": [
        "## Load GSM8K dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E47hYa8dEXiq"
      },
      "outputs": [],
      "source": [
        "gsm8k = datasets.load_dataset(\"gsm8k\", \"main\", cache_dir='/tmp')\n",
        "gsm8k_train, gsm8k_test = gsm8k['train'], gsm8k['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReheKSODEXiq"
      },
      "outputs": [],
      "source": [
        "# @title Testing library\n",
        "\n",
        "def find_numbers(x: str) -\u003e list[str]:\n",
        "  \"\"\"Finds all numbers in a string.\"\"\"\n",
        "  # Search for number, possibly negative (hyphen), with thousand separators\n",
        "  # (comma), and with a decimal point (period inbetween digits).\n",
        "  numbers = re.compile(\n",
        "      r'-?[\\d,]*\\.?\\d+',\n",
        "      re.MULTILINE | re.DOTALL | re.IGNORECASE,\n",
        "  ).findall(x)\n",
        "  return numbers\n",
        "\n",
        "\n",
        "def find_number(x: str,\n",
        "                answer_delimiter: str = 'The answer is') -\u003e str:\n",
        "  \"\"\"Finds the most relevant number in a string.\"\"\"\n",
        "  # If model uses the answer delimiter, then select the first number following\n",
        "  # that format.\n",
        "  if answer_delimiter in x:\n",
        "    answer = x.split(answer_delimiter)[-1]\n",
        "    numbers = find_numbers(answer)\n",
        "    if numbers:\n",
        "      return numbers[0]\n",
        "\n",
        "  # In general, select the last number in the string.\n",
        "  numbers = find_numbers(x)\n",
        "  if numbers:\n",
        "    return numbers[-1]\n",
        "  return ''\n",
        "\n",
        "\n",
        "def maybe_remove_comma(x: str) -\u003e str:\n",
        "  # Example: 5,600 -\u003e 5600\n",
        "  return x.replace(',', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXoCKMi9EXir"
      },
      "outputs": [],
      "source": [
        "# @title GSM8K Prompts\n",
        "\n",
        "PREAMBLE = \"\"\"As an expert problem solver solve step by step the following mathematical questions.\"\"\"\n",
        "\n",
        "# The default gsm8k prompt from the CoT paper\n",
        "# https://arxiv.org/pdf/2201.11903.pdf page 35.\n",
        "\n",
        "PROMPT = \"\"\"Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah's sister had 42. That means there were originally 32 + 42 = 74 chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 = 20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers. The answer is 29.\n",
        "\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in beginning, so now she has $23 - $15 = $8. The answer is 8.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LoeozW4EXir"
      },
      "source": [
        "## Load and prepare your LLM's checkpoint for use with Flax.\n",
        "\n",
        "Start by loading the weights of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7s15QMbbEXir"
      },
      "outputs": [],
      "source": [
        "# Load parameters\n",
        "params = recurrentgemma.load_parameters(ckpt_path, 'single_device')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tkY-sLuEXir"
      },
      "source": [
        "Then load the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_n0KePI2EXir"
      },
      "outputs": [],
      "source": [
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.Load(str(vocab_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wvhxNb1EXir"
      },
      "source": [
        "Finally, build a sampler from the model configuration deduced from the checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "51WOHSzVEXir"
      },
      "outputs": [],
      "source": [
        "model_config = recurrentgemma.GriffinConfig.from_flax_params_or_variables(params, preset=recurrentgemma.Preset.RECURRENT_GEMMA_2B_V1)\n",
        "model = recurrentgemma.Griffin(model_config)\n",
        "\n",
        "# Create a sampler with the right param shapes for the GSM8K prompt below\n",
        "sampler = recurrentgemma.Sampler(\n",
        "    model=model,\n",
        "    vocab=vocab,\n",
        "    params=params,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NhlBMaIEXir"
      },
      "source": [
        "## Main Evaluation loop\n",
        "\n",
        "You should expect a score of 19.33% with the 2B model, on TPUv2. The evals take some time to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iHxQeQ4hEXir"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "all_responses = {}\n",
        "short_responses = {}\n",
        "idx = 0\n",
        "correct = 0\n",
        "\n",
        "TEMPLATE = \"\"\"\n",
        "Q: {question}\n",
        "A:\"\"\"\n",
        "\n",
        "for task_id, problem in enumerate(gsm8k_test):\n",
        "\n",
        "  if task_id in all_responses: continue\n",
        "\n",
        "  # Print Task ID\n",
        "  print(f\"task_id {task_id}\")\n",
        "\n",
        "  # Formulate and print the full prompt\n",
        "  full_prompt = (PREAMBLE +'\\n\\n' + PROMPT + '\\n' +\n",
        "                 TEMPLATE.format(question=problem['question']))\n",
        "\n",
        "  input_batch = [full_prompt]\n",
        "  response = sampler(input_strings=input_batch, total_generation_steps=1024)\n",
        "  print(response.text)\n",
        "\n",
        "  all_responses[task_id] = response.text[0].split('\\nQ:')[0]\n",
        "  short_responses[task_id] = maybe_remove_comma(find_number(all_responses[task_id]))\n",
        "  print(f\"Short answer: {short_responses[task_id]}\")\n",
        "  try:\n",
        "    correct += float(maybe_remove_comma(\n",
        "        find_number(problem['answer']))) == float(short_responses[task_id])\n",
        "  except:\n",
        "    correct += maybe_remove_comma(\n",
        "        find_number(problem['answer'])) == maybe_remove_comma(\n",
        "            find_number(short_responses[task_id]))\n",
        "  print('-'*40)\n",
        "  print(f\"Ground truth answer {problem['answer']}\")\n",
        "  print(f\"Short ground truth answer {find_number(problem['answer'])}\")\n",
        "  print(f\"Correct: {correct} out of {idx+1}\")\n",
        "  print(\"=\"*40)\n",
        "  idx += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "last_runtime": {},
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1bLV8kyT69f6EUJs-t7SA0dAWkAVnzPSr",
          "timestamp": 1712928508699
        },
        {
          "file_id": "19MpsRRDNXIi1c2CXFInVuIZe8xyQCznB",
          "timestamp": 1712921403657
        },
        {
          "file_id": "/piper/depot/google3/third_party/py/recurrentgemma/colabs/gsm8k_eval.ipynb?workspaceId=gmuraru:add_gsm8k_sampling::citc",
          "timestamp": 1712745612092
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
